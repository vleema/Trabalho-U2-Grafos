\chapter{Implementação}
\label{ch:implementation}

Nesse capítulo serão mostradas as implementações reais de cada
algoritmo, acrescidas de comentários que elucidem as escolhas de
implementações tomadas.

\section{Algoritmos de Árvore Geradora Mínima}

\subsection{Algoritmo de Kruskal}

\begin{lstlisting}[language=Rust, caption={Construtor de Kruskal: KruskalIter::new}]
pub fn new(graph: &'a G) -> Self {
    let nodes: Vec<T> = graph.nodes().collect();
    let accepted_adj: HashMap<T, HashSet<T>> = HashMap::with_capacity(nodes.len());

    let mut seen: HashSet<(T, T)> = HashSet::with_capacity(nodes.len() * 2);
    let mut edges: Vec<(T, T, i32)> = Vec::new();

    for &u in &nodes {
        for (v, w) in graph.weighted_neighbors(u) {
            let (a, b) = if u <= v { (u, v) } else { (v, u) };
            if seen.insert((a, b)) {
                edges.push((a, b, w));
            }
        }
    }

    edges.sort_by(|(ua, va, wa), (ub, vb, wb)| {
        wa.cmp(wb).then_with(|| ua.cmp(ub)).then_with(|| va.cmp(vb))
    });

    KruskalIter {
        _graph: graph,
        edges,
        idx: 0,
        accepted_adj,
    }
}
\end{lstlisting}

\begin{lstlisting}[language=Rust, caption={Iterador de Kruskal: impl Iterator for KruskalIter (next)}]
impl<'a, T, G> Iterator for KruskalIter<'a, T, G>
where
    T: Node + Ord,
    G: UndirectedGraph<T> + WeightedGraph<T, i32> + ?Sized,
{
    type Item = KruskalEvent<T>;

    fn next(&mut self) -> Option<Self::Item> {
        if self.idx < self.edges.len() {
            let (u, v, w) = self.edges[self.idx];
            self.idx += 1;

            if !self.connected_by_accepted(u, v) {
                self.accepted_adj.entry(u).or_default().insert(v);
                self.accepted_adj.entry(v).or_default().insert(u);
                Some(KruskalEvent::EdgeAdded((u, v, w)))
            } else {
                Some(KruskalEvent::EdgeSkipped((u, v, w)))
            }
        } else {
            None
        }
    }
}
\end{lstlisting}

A função \texttt{new} prepara previamente todos os dados necessários para a execução incremental do Algoritmo de Kruskal. Ela coleta todas as arestas do grafo, organiza‑as em um vetor e as ordena pelo peso, garantindo que possam ser examinadas da menor para a maior. Também é inicializada a estrutura \texttt{accepted\_adj}, que representa o subgrafo formado apenas pelas arestas já selecionadas na construção da solução.

A lógica do algoritmo é realizada de forma incremental no método \texttt{next()}. A cada chamada, o iterador processa a próxima aresta da lista ordenada. Para decidir se ela deve ser incluída na árvore geradora, o método verifica se seus vértices já estão conectados no subgrafo parcial armazenado em \texttt{accepted\_adj}. Caso ainda estejam conectados, isto é, caso a inclusão da aresta não forme um ciclo, a aresta é incorporada à solução e registrada na estrutura \texttt{accepted\_adj}. 

Ao final das iterações, as arestas acumuladas em \texttt{accepted\_adj} constituem o resultado do algoritmo.

\subsection{Algoritmo de Prim}

\begin{lstlisting}[language=Rust, caption={Construtor de Prim: PrimIter::new}]
pub fn new(graph: &'a G) -> Self {
    let nodes: Vec<T> = graph.nodes().collect();
    let mut visited: HashSet<T> = HashSet::with_capacity(nodes.len());
    let mut heap = BinaryHeap::new();

    if let Some(&s) = nodes.first() {
        visited.insert(s);
        for (v, w) in graph.weighted_neighbors(s) {
            let (a, b) = if s <= v { (s, v) } else { (v, s) };
            heap.push(Reverse((w, a, b)));
        }
    }

    PrimIter {
        _graph: graph,
        visited,
        heap,
        nodes_len: nodes.len(),
    }
}
\end{lstlisting}

\begin{lstlisting}[language=Rust, caption={Iterador de Prim: impl Iterator for PrimIter (next)}]
impl<'a, T, G> Iterator for PrimIter<'a, T, G>
where
    T: Node + Ord,
    G: UndirectedGraph<T> + WeightedGraph<T, i32> + ?Sized,
{
    type Item = PrimEvent<T>;

    fn next(&mut self) -> Option<Self::Item> {
        if self.visited.len() >= self.nodes_len {
            return None;
        }

        while let Some(Reverse((w, u, v))) = self.heap.pop() {
            let u_vis = self.visited.contains(&u);
            let v_vis = self.visited.contains(&v);

            if u_vis && v_vis {
                return Some(PrimEvent::EdgeSkipped(u, v, w));
            }

            if u_vis ^ v_vis {
                let new = if u_vis { v } else { u };
                let (a_out, b_out) = if u <= v { (u, v) } else { (v, u) };
                self.visited.insert(new);
                for (nv, w2) in self._graph.weighted_neighbors(new) {
                    let (aa, bb) = if new <= nv { (new, nv) } else { (nv, new) };
                    self.heap.push(Reverse((w2, aa, bb)));
                }
                return Some(PrimEvent::EdgeAdded(a_out, b_out, w));
            }

            continue;
        }

        None
    }
}
\end{lstlisting}

A função \texttt{new()} prepara previamente todos os dados necessários para a execução incremental do Algoritmo de Prim. Inicialmente, escolhe-se um vértice arbitrário como ponto de partida (neste caso, o primeiro retornado por \texttt{graph.nodes()}). Esse vértice é marcado como visitado e todas as suas arestas incidentes são inseridas em um heap mínimo, que servirá como estrutura de prioridade para selecionar sempre a próxima aresta de menor peso que expande a árvore. São também inicializados os conjuntos \texttt{visited} e \texttt{heap}, que representarão, respectivamente, os vértices já incorporados à solução e o conjunto de arestas candidatas que conectam o conjunto visitado ao restante do grafo.

A lógica do algoritmo é realizada de forma incremental no método \texttt{next()}. A cada chamada, o iterador remove do heap a aresta de menor peso disponível. Se essa aresta conecta um vértice já visitado a um ainda não visitado, então ela é aceita na árvore geradora mínima. O vértice recém‑incluído é adicionado a \texttt{visited}, e todas as suas arestas são inseridas no heap, permitindo que novas expansões sejam consideradas. Caso contrário, se a aresta conecta dois vértices já visitados, ela é descartada, pois sua inclusão criaria um ciclo.

Ao final das iterações, quando todos os vértices tiverem sido incorporados ao conjunto \texttt{visited}, o método \texttt{next()} deixa de produzir eventos e a execução se encerra. As arestas aceitas ao longo do processo formam a árvore geradora mínima do grafo.

\section{Algoritmos de Caminho Mais Curto}

\subsection{Algoritmo de Dijkstra}
Para a implementação de Dijkstra foi elaborado a seguinte \textit{struct}:
\begin{listing}[H]
  \caption{Estrutura do iterador de Dijkstra}
\begin{minted}{rust}
struct DijkstraResult<Node, Weight> {
    route: HashMap<Node, (Weight, Option<Node>)>,
}
\end{minted}
\end{listing}

Esta estrutura é responsável por armazenar um dicionário que contém o
resultado do Algortimo de Dijkstra, onde cada chave é um nó que
aponta para uma dupla, que indica o predecessor até o nó e também a
distância dele da origem.

\begin{listing}[H]
  \caption{Implementação do Algoritmo de Dijkstra}
\begin{minted}{rust}
impl<N: Node, W: Weight> DijkstraResult<N, W> {
    pub fn new(graph: &(impl WeightedGraph<N, W> + ?Sized), start: N) -> Self {
        let mut route: HashMap<N, (W, Option<N>)> = HashMap::new();
        let mut visited: HashSet<N> = HashSet::new();
        let mut distance: HashMap<N, W> = HashMap::new();
        let mut pred: HashMap<N, Option<N>> = HashMap::new();
        distance.insert(start, W::zero());
        pred.insert(start, None);

        for (neighbor, weight) in graph.weighted_neighbors(start) {
            pred.insert(neighbor, Some(start));
            distance.insert(neighbor, weight);
        }

        loop {
            let mut unvisited_node: Option<(N, W)> = None;
            for node in graph.nodes() {
                if !visited.contains(&node)
                    && let Some(distance) = distance.get(&node)
                    && (unvisited_node.is_none()
                        || (unvisited_node.is_some() && distance < &unvisited_node.unwrap().1))
                {
                    unvisited_node = Some((node, *distance));
                }
            }

            match unvisited_node {
                None => break,
                Some((node, node_weight)) => {
                    visited.insert(node);

                    for (neighbor, weight) in graph.weighted_neighbors(node) {
                        if !visited.contains(&neighbor) {
                            let new_distance = weight + node_weight;

                            match distance.get(&neighbor) {
                                Some(&neighbor_distance) => {
                                    if neighbor_distance > new_distance {
                                        distance.insert(neighbor, new_distance);
                                        pred.insert(neighbor, Some(node));
                                    }
                                }
                                None => {
                                    distance.insert(neighbor, new_distance);
                                    pred.insert(neighbor, Some(node));
                                }
                            }
                        }
                    }

                    let mut parent: Option<N> = None;
                    if let Some(opt) = pred.get(&node) {
                        parent = *opt;
                    }

                    route.insert(node, (node_weight, parent));
                }
            }
        }
        Self { route }
    }
}
\end{minted}
\end{listing}

A função \textit{new} é responsável por executar o Algoritmo de
Dijkstra e retornar seu resultado. Para manter o controle de vértices
visitados, a distância até eles e também seus predecessores, criamos
dicionários e conjuntos auxiliares para este processo.

O algoritmo inicia definindo a distância e o predecessor do nó
inicial como 0 e \textit{None}, respectivamente, para então definir
os mesmos elementos para os seus vizinhos, mas sem marcar ninguém
como visitado. Após isso, inicia-se o loop principal: a cada
iteração, é buscado o vértice com menor distância, para que este seja
visitado e os seus vizinhos sejam relaxados, ou seja, tenham sua
distância e predecessor atualizados caso seja vantajoso; ao visitar
um vértice, note que ele é salvo no dicionário \texttt{route}, onde o
vértice é a chave que aponta para a dupla com a sua distância e
também seu predecessor. Ao acabar os nós não visitados, a função
retorna a rota completa.

Para encontrar, então, o caminho entre dois vértices, o consumidor da
função pode acessar o dicionário \texttt{route} a partir do vértice
final e ir explorando seus predecessores até encontrar o nó inicial.
Isso traz solidez e isolamento para o algoritmo, que é capaz de
cumprir com eficácia seu objetivo principal sem se preocupar com o
modo em que as informações serão usadas.

\subsection{Algoritmo de Floyd-Warshall}

Para o algoritmo de
Floyd-Warshall~(\ref{sec:pseudocode_floyd-warshall}), inicialmente definimos uma
estrutura, que vai representar o retorno da função:

\begin{listing}[H]
  \caption{Estrutura de resultado do Algoritmo Floyd-Warshall}
\begin{minted}{rust}
struct FloydWarshallResult<Node, Weight> {
    dist: HashMap<Node, HashMap<Node, Weight>>,
    pred: HashMap<Node, HashMap<Node, Node>>,
}
\end{minted}
\end{listing}

Ela é genérica a qualquer tipo de nó e de peso, identificados por
\texttt{Node} e \texttt{Weight}. \texttt{dist} representa a matriz de
distâncias do resultado do algoritmo e \texttt{pred} representa a
matriz de predecessores. Para o resultado ser genérico a qualquer
tipo, é necessário implementar a matriz através de tabelas hash que
indexam nós e armazenam outras tabelas hash, as quais indexam nó e
custo (no caso da matriz de distâncias). De forma que um acesso
\texttt{dist[i][j]} represente a
distância entre o vértice \texttt{i} e o vértice \texttt{j}.

Após definir a estrutura, definimos a interface do algoritmo como sendo o
construtor dessa estrutura, nomeado de \texttt{new}:
\begin{listing}[H]
  \caption{Interface do algoritmo de Floyd-Warshall}
\begin{minted}{rust}
impl<N: Node, W: Weight> FloydWarshallResult<N, W> {
    fn new(g: &(impl WeightedGraph<N, W> + ?Sized)) -> Self;
}
\end{minted}
\end{listing}

O algoritmo espera a implementação de um grafo ponderado \texttt{g}
que pode ter seu tamanho conhecido ou não em tempo de compilação (com
a restrição de traço \texttt{?Sized}). \texttt{N} e \texttt{W} são o
tipo do nó e do custo, e são restritos pelos traços
\texttt{Node} e \texttt{Weight} respectivamente.

Começando a implementação, definimos as duas estruturas que vão
constituir o resultado e as inicializamos:

\begin{minted}{rust}
let mut dist = HashMap::with_capacity(g.order());
let mut pred = HashMap::with_capacity(g.order());
for n in g.nodes() {
    let mut neighbors_dist = HashMap::new();
    let mut neighors_pred = HashMap::new();

    neighbors_dist.insert(n, W::zero());
    neighors_pred.insert(n, n);

    for (neighbor, weight) in g.weighted_neighbors(n) {
        neighbors_dist.insert(neighbor, weight);
        neighors_pred.insert(neighbor, n);
    }

    dist.insert(n, neighbors_dist);
    pred.insert(n, neighors_pred);
}
\end{minted}

Essa inicialização garante que os custos e predecessores dos vértices
adjacentes já sejam incorporados na estrutura. Entretanto, note que
as outras distâncias e predecessores não são inicializados, diferente
de como é descrito no
pseudocódigo~\ref{sec:pseudocode_floyd-warshall}. Note também que
explicitamente definimos \texttt{pred[i][i]} como \texttt{i} e
\texttt{dist[i][i]} como \texttt{0} nessa implementação. Fizemos isso
para manter a fidelidade a implementações mais clássicas do
algoritmo, mas não é obrigatório.

Antes de partir para o cerne da implementação, definimos uma função
anônima denominada \texttt{unwrap\_dist}, para lidar com o acesso
seguro as tabelas hash de rust, especificamente a \texttt{dist}. Pois
o acesso usando operador \texttt{[]} pode causar pânicos se a chave
não existir, o que no nosso caso não é garantido para o segundo acesso.

\begin{minted}{rust}
let unwrap_dist = |dist: &HashMap<N, HashMap<N, W>>, i, j| {
    dist[&i].get(&j).copied().unwrap_or(W::max_value())
};
\end{minted}

No caso em que a segunda chave não exista, retornamos o valor máximo do tipo
numérico do custo (\texttt{W::max\_value()}) ao invés do valor que
existiria no acesso.

Por fim, partimos para o cerne da implementação, o loop principal do algoritmo:

\begin{minted}{rust}
for k in g.nodes() {
    for i in g.nodes() {
        for j in g.nodes() {
            let dist_ik = unwrap_dist(&dist, i, k);
            let dist_kj = unwrap_dist(&dist, k, j);
            let dist_ij = unwrap_dist(&dist, i, j);
            if let Some(sum) = dist_ik.checked_add(&dist_kj)
                && sum < dist_ij
            {
                dist.entry(i).and_modify(|ds| {
                    ds.entry(j)
                        .and_modify(|d| *d = sum)
                        .or_insert(sum);
                });
                let pred_kj = pred[&k][&j];
                pred.entry(i).and_modify(|ps| {
                    ps.entry(j)
                        .and_modify(|p| *p = pred_kj)
                        .or_insert(pred_kj);
                });
            }
        }
    }
}

Self { dist, pred }
\end{minted}

A implementação segue o algoritmo clássico em semântica, entretanto,
com diversas checagens de segurança. Por exemplo, ao checar se
\texttt{k} melhora a distância entre \texttt{i} e \texttt{j}, é
primeiro verificado se a soma entre \texttt{dist[i][k]} e
\texttt{dist[k][j]} causa overflow de inteiro, usando o método
\texttt{checked\_add} de um tipo numérico:

\begin{minted}{rust}
if let Some(sum) = dist_ik.checked_add(&dist_kj)
    && sum < dist_ij { ... }
\end{minted}

Além disso, ao invés de alterar diretamente o predecessor e distância de
$ij$ quando é necessário, alteramos ou inserimos o novo valor, visto
que não é garantido que \texttt{pred[i][j]} ou \texttt{dist[i][j]}
existiam previamente.

\begin{minted}{rust}
dist.entry(i).and_modify(|ds| {
    ds.entry(j)
        .and_modify(|d| *d = sum)
        .or_insert(sum);
});
let pred_kj = pred[&k][&j];
pred.entry(i).and_modify(|ps| {
    ps.entry(j)
        .and_modify(|p| *p = pred_kj)
        .or_insert(pred_kj);
});
\end{minted}

A implementação completa do algoritmo é a seguinte:

\begin{listing}[H]
  \caption{Implementação do algoritmo de Floyd-Warshall}
  \begin{minted}{rust}
impl<N: Node, W: Weight> FloydWarshallResult<N, W> {
    pub fn new(g: &(impl WeightedGraph<N, W> + ?Sized)) -> Self {
        let mut dist = HashMap::with_capacity(g.order());
        let mut pred = HashMap::with_capacity(g.order());
        for n in g.nodes() {
            let mut neighbors_dist = HashMap::new();
            let mut neighors_pred = HashMap::new();

            neighbors_dist.insert(n, W::zero());
            neighors_pred.insert(n, n);

            for (neighbor, weight) in g.weighted_neighbors(n) {
                neighbors_dist.insert(neighbor, weight);
                neighors_pred.insert(neighbor, n);
            }

            dist.insert(n, neighbors_dist);
            pred.insert(n, neighors_pred);
        }

        let unwrap_dist = |dist: &HashMap<N, HashMap<N, W>>, i, j| {
            dist[&i].get(&j).copied().unwrap_or(W::max_value())
        };

        for k in g.nodes() {
            for i in g.nodes() {
                for j in g.nodes() {
                    let dist_ik = unwrap_dist(&dist, i, k);
                    let dist_kj = unwrap_dist(&dist, k, j);
                    let dist_ij = unwrap_dist(&dist, i, j);
                    if let Some(sum) = dist_ik.checked_add(&dist_kj)
                        && sum < dist_ij
                    {
                        dist.entry(i).and_modify(|ds| {
                            ds.entry(j)
                                .and_modify(|d| *d = sum)
                                .or_insert(sum);
                        });
                        let pred_kj = pred[&k][&j];
                        pred.entry(i).and_modify(|ps| {
                            ps.entry(j)
                                .and_modify(|p| *p = pred_kj)
                                .or_insert(pred_kj);
                        });
                    }
                }
            }
        }

        Self { dist, pred }
    }
}
  \end{minted}
\end{listing}

\section{Algoritmos de Grafos Eulerianos}
